Namespace(output_dir='li', modelname='etcaps', num_datapoints=10)
etcaps
C:\Users\coeze\Documents\honours_dissertation_final\venv\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\coeze\Documents\honours_dissertation_final\venv\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Path to dataset files: C:\Users\coeze\.cache\kagglehub\datasets\sautkin\imagenet1k1\versions\2
{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875, 'crop_mode': 'center'}
  0%|                                                                                                             | 0/10 [00:00<?, ?it/s]C:\Users\coeze\Documents\honours_dissertation_final\venv\Lib\site-packages\torch\functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\TensorShape.cpp:3638.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
tensor([[0.0063, 0.0063, 0.0063, 0.0063, 0.0065, 0.0063, 0.0063, 0.0063, 0.0063,
         0.0068, 0.0068, 0.0068, 0.0068, 0.0070, 0.0068, 0.0068, 0.0068, 0.0068,
         0.0070, 0.0070, 0.0070, 0.0070, 0.0073, 0.0070, 0.0070, 0.0070, 0.0070,
         0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068,
         0.0071, 0.0071, 0.0071, 0.0071, 0.0072, 0.0071, 0.0071, 0.0071, 0.0071,
         0.0072, 0.0072, 0.0072, 0.0072, 0.0075, 0.0072, 0.0072, 0.0072, 0.0072,
         0.0065, 0.0065, 0.0065, 0.0065, 0.0067, 0.0065, 0.0065, 0.0065, 0.0065,
         0.0070, 0.0070, 0.0070, 0.0070, 0.0072, 0.0070, 0.0070, 0.0070, 0.0070,
         0.0075, 0.0075, 0.0075, 0.0075, 0.0073, 0.0075, 0.0075, 0.0075, 0.0075,
         0.0065, 0.0065, 0.0065, 0.0065, 0.0066, 0.0065, 0.0065, 0.0065, 0.0065,
         0.0075, 0.0075, 0.0075, 0.0075, 0.0075, 0.0075, 0.0075, 0.0075, 0.0075,
         0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,
         0.0067, 0.0067, 0.0067, 0.0067, 0.0067, 0.0067, 0.0067, 0.0067, 0.0067,
         0.0068, 0.0068, 0.0068, 0.0068, 0.0069, 0.0068, 0.0068, 0.0068, 0.0068,
         0.0078, 0.0078, 0.0078, 0.0078, 0.0075, 0.0078, 0.0078, 0.0078, 0.0078,
         0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
op <built-in method grid_sampler_2d_backward of PyCapsule object at 0x000001A61D7B39F0>
  0%|                                                                                                             | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Users\coeze\Documents\honours_dissertation_final\lie-deriv\exps_e2e.py", line 717, in <module>
    main(args)
  File "C:\Users\coeze\Documents\honours_dissertation_final\lie-deriv\exps_e2e.py", line 661, in main
    get_metrics(args, "Imagenet_train", imagenet_train_loader, model),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\lie-deriv\exps_e2e.py", line 604, in get_metrics
    lee_metrics = eval_average_metrics_wstd(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\lie-deriv\exps_e2e.py", line 329, in eval_average_metrics_wstd
    dfs.append(metrics(minibatch))
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\lie-deriv\exps_e2e.py", line 583, in get_lee_metrics
    "trans_x_deriv": translation_lie_deriv(model_probs, x, axis="x"),
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\lie-deriv\exps_e2e.py", line 448, in translation_lie_deriv
    lie_deriv = jvp(shifted_model, t, torch.ones_like(t, requires_grad=True))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\lie-deriv\exps_e2e.py", line 419, in jvp
    vJ = torch.autograd.grad(y, [x], [v], create_graph=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\venv\Lib\site-packages\torch\autograd\__init__.py", line 496, in grad
    result = _engine_run_backward(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\venv\Lib\site-packages\torch\autograd\graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\venv\Lib\site-packages\torch\autograd\function.py", line 307, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\src\grid_sampler.py", line 57, in backward
    grad_input, grad_grid = _GridSample2dBackward.apply(grad_output, input, grid)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\venv\Lib\site-packages\torch\autograd\function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\coeze\Documents\honours_dissertation_final\src\grid_sampler.py", line 67, in forward
    grad_input, grad_grid = op(grad_output, input, grid, 0, 0, False)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Overloaded torch operator invoked from Python failed to match any schema:
aten::grid_sampler_2d_backward() is missing value for argument 'output_mask'. Declaration: aten::grid_sampler_2d_backward(Tensor grad_output, Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners, bool[2] output_mask) -> (Tensor, Tensor)

aten::grid_sampler_2d_backward() is missing value for argument 'output_mask'. Declaration: aten::grid_sampler_2d_backward.out(Tensor grad_output, Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners, bool[2] output_mask, *, Tensor(a!) out0, Tensor(b!) out1) -> (Tensor(a!), Tensor(b!))
